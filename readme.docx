Steps to Configure and Run the Fabric Data Pipeline
1. Create a Fabric Workspace.
2. Create a OneLake named testLake (or any suitable name), and update the name in the JSON configuration file.
3. Create a SQL Database, e.g., controlDB.
4. Run the schema scripts on the controlDB to create required tables (e.g., PipelineDetails, BusinessSourceDetails).
5. Run the insertion scripts to populate configuration data into the controlDB.
6. Upload sample files to the OneLake file area under the appropriate Business Outcome (BO) folder (e.g., BO2, BO3).
7. Create the main pipeline and paste in the corresponding pipeline code.
8. Create a child pipeline using the provided JSON code.
9. Set up the OneLake connection in the pipeline.
10. Set up the controlDB SQL connection in the pipeline.
11. Save all configurations and pipelines.
12. Run the main pipeline with BO2 as the input parameter.
✅ Check OneLake – two target tables should be created.
13. Run the main pipeline with BO3 as the input parameter.
✅ Check OneLake – two target tables should be created.
14. Add a new Business Outcome (e.g., BO4) by inserting appropriate metadata into the control database.
15. Upload your sample file to the OneLake file area under the BO4 folder.
16. Run the main pipeline with BO4 as the input parameter and verify the result.
